## 3.10-4.6 科研周记

### 第一周（3.10-3.16）

1. 简单学习了映射的概念；

2. 精读了一篇文献：《A deep learning digital biomarker to detect hypertension and stratify cardiovascular risk from the electrocardiogram》，其核心工作包括两个：

   * 构建一个HTN-AI深度学习模型，输入12导联ECG信号，输出HTN-AI score（高血压预测概率），将HTN-AI score作为数字生物标志物用于诊断高血压；
   * 将数字生物标志物HTN-AI score通过竞争风险模型分析其对心血管疾病的风险预测能力。

   学习到了“构建数字生物标志物并研究其风险预测能力”这一研究思路，学习到了多任务学习；

3. 学完了《回归分析》中简单线性回归的后半部分，理解了为什么线性回归的预测中，预测 $y$ 时方差比预测 $E(y)$ 多了个 $1$，这是因为 $y$ 是随机变量，$y-\hat{y}$ 的方差是二者方差之和，而 $E(y)$ 是常数，$E(y)-\hat{y}$ 的方差是后者的方差；理解了残差并非模型假设中的随机误差，残差并不是相互独立的，详细解释如下：

   误差项 $\varepsilon_i$
   - **定义**：误差项 $\varepsilon_i$ 是模型中未被解释的部分，表示观测值 $Y_i$ 与真实期望值 $\mu_i = \beta_0 + \beta_1 X_i$ 之间的差异。
   - **假设**：通常假设 $\varepsilon_i$ 独立同分布（i.i.d.），服从正态分布 $\mathcal{N}(0, \sigma^2)$。这是线性回归模型的基本假设之一。

   残差 $e_i$
   - **定义**：残差 $e_i$ 是观测值 $Y_i$ 与拟合值 $\hat{Y}_i$ 之间的差异，即 $e_i = Y_i - \hat{Y}_i$。
   - **性质**：由于最小二乘估计方法的约束条件，残差之间存在相关性。例如，在简单线性回归中：
     $$
     \sum_{i=1}^n e_i = 0, \quad \sum_{i=1}^n x_i e_i = 0
     $$
     这些约束条件表明残差不是完全独立的。
   
   虽然残差不相互独立，当样本量足够大时，残差的协方差矩阵趋于对角阵，并且残差是随机误差的估计值，残差仍能反映随机误差的某些性质。因此，残差分析的目的是通过可观测的残差模式，推断不可观测的误差项是否符合模型假设，从而指导模型改进，残差分析是诊断工具，而非严格数学证明。

### 第二周（3.17-3.23）

1. 推导了矩阵形式的最小二乘法，复习了矩阵求导法，学习了多元线性回归前半部分；
1. 学习完了《回归分析》的多元线性回归；
1. 学习了概率论的第三章“条件概率”的前半部分；
1. 学习了DeLong Test；
1. 学习了《回归分析》变量选择一章。

### 第三周（3.24-3.30）

1. 线性回归、线性混合效应模型均不能通过响应变量的正态性来判断是否满足正态性假设，正态性假设是对残差或者随机效应而言的，响应变量 $y$ 的正态性是条件正态分布，而当其无条件分布（边际分布）未必是正态的；
1. Fisher Z检验既能检验单个相关系数，又能检验两个相关系数；
1. 学习了有序样品聚类；
1. 学习了《回归分析》回归诊断前半部分，学习了删除学生化残差、杠杆值、库克距离，学习了异方差线性回归诊断（残差图和残差与x的等级相关系数）及加权最小二乘法；
1. 学完了概率论第三章《条件概率和独立性》，重点学习了“$P(\cdot|F)$是概率”这一节，学习了可以把$P(\cdot|F)$看做$P(E)$，这样方便处理多个条件的条件概率，同时学习了条件独立和序贯地补充信息，序贯地补充信息的前提是条件独立；
1. 学完了概率论第四章《随机变量》，学习了泊松范例，即在独立或弱相依的条件下，只要各事件发生的概率都较小，事件发生的数量就近似地服从泊松分布，并不要求各个事件发生的概率相同；
1. 学习了瑞利商和广义瑞利商。

### 第四周（3.31-4.6）

1. 学习了分布“厚尾”时下理论矩不存在，此时就算能计算出样本均值，当随着样本量 $n$ 增大时，样本均值不会收敛；
1. 学习了C-index，它的思想是就是模型预测结果与实际观测结果的一致性比例，具体做法是对样本进行两两配对，如果预测生存概率高的样本的生存时间长于另一个样本，则认为预测结果与实际结果一致；
1. 简单学习了因果推断，学习了三大框架：关联、干预和反事实，关联包括链式、叉式和对撞式三种结构，干预学习了前门准则和后门准则；
1. 简单学习了因果森林，其核心原理是将处理效应作为分裂标准，最大化不同子节点之间治疗效应的异质性，最小化同一子节点间治疗效应的异质性。因果森林用到了诚实估计，它的含义是将数据分成至少两个独立的子集，一个用于构建树的结构（选择分裂），另一个用于估计叶节点内的目标变量值，这样可以减少效应估计过拟合和出现偏差的风险。
